{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37071e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1427917464885682177</td>\n",
       "      <td>2021-08-18 08:57:07</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>@CypherPaints @RD_btc where's the dip? https:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1427776452053901318</td>\n",
       "      <td>2021-08-17 23:36:47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@mutatrum @SGBarbour @Endorsen @NickSzabo4 @ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1427759906170548227</td>\n",
       "      <td>2021-08-17 22:31:02</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>@sovereignhodler @paoloardoino @Liquid_BTC @bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1427756195390136323</td>\n",
       "      <td>2021-08-17 22:16:18</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>@Esky33junglist @Mandrik @TheGuySwann confiden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1427755868171509761</td>\n",
       "      <td>2021-08-17 22:15:00</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>@paoloardoino i think for longer-term cold sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29864</th>\n",
       "      <td>1361157185946836995</td>\n",
       "      <td>2021-02-15 03:35:36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@AriDavidPaul @Readwiseio save thread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29865</th>\n",
       "      <td>1360861621350932482</td>\n",
       "      <td>2021-02-14 08:01:08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@SahilBloom @Readwiseio save thread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29866</th>\n",
       "      <td>1360479655199838210</td>\n",
       "      <td>2021-02-13 06:43:20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@yassineARK @Readwiseio save thread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29867</th>\n",
       "      <td>1358997025656696836</td>\n",
       "      <td>2021-02-09 04:31:54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@markoff H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29868</th>\n",
       "      <td>1358914916506169345</td>\n",
       "      <td>2021-02-08 23:05:38</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>https://t.co/ynlEHiMvpa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29869 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id           created_at  favorite_count  \\\n",
       "0      1427917464885682177  2021-08-18 08:57:07              10   \n",
       "1      1427776452053901318  2021-08-17 23:36:47               0   \n",
       "2      1427759906170548227  2021-08-17 22:31:02               3   \n",
       "3      1427756195390136323  2021-08-17 22:16:18              10   \n",
       "4      1427755868171509761  2021-08-17 22:15:00              13   \n",
       "...                    ...                  ...             ...   \n",
       "29864  1361157185946836995  2021-02-15 03:35:36               0   \n",
       "29865  1360861621350932482  2021-02-14 08:01:08               0   \n",
       "29866  1360479655199838210  2021-02-13 06:43:20               0   \n",
       "29867  1358997025656696836  2021-02-09 04:31:54               0   \n",
       "29868  1358914916506169345  2021-02-08 23:05:38               2   \n",
       "\n",
       "       retweet_count                                               text  \n",
       "0                  1  @CypherPaints @RD_btc where's the dip? https:/...  \n",
       "1                  0  @mutatrum @SGBarbour @Endorsen @NickSzabo4 @ha...  \n",
       "2                  0  @sovereignhodler @paoloardoino @Liquid_BTC @bi...  \n",
       "3                  1  @Esky33junglist @Mandrik @TheGuySwann confiden...  \n",
       "4                  1  @paoloardoino i think for longer-term cold sto...  \n",
       "...              ...                                                ...  \n",
       "29864              0              @AriDavidPaul @Readwiseio save thread  \n",
       "29865              0                @SahilBloom @Readwiseio save thread  \n",
       "29866              0                @yassineARK @Readwiseio save thread  \n",
       "29867              0                                         @markoff H  \n",
       "29868              0                            https://t.co/ynlEHiMvpa  \n",
       "\n",
       "[29869 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.decomposition import NMF\n",
    "import nltk\n",
    "\n",
    "\n",
    "import glob\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import string\n",
    "df = pd.read_csv('bitcoin_twitter.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0401723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "alphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "rid_handles = lambda x: re.sub('@\\S+', ' ', x)\n",
    "links = lambda x: re.sub('https?:\\/\\/\\S+', ' ', x)\n",
    "breaks = lambda x: re.sub('\\n', ' ', x)\n",
    "df['text'] = df['text'].map(rid_handles).map(links).map(breaks).map(alphanumeric).map(punc_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af039c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f5c4c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1427917464885682177</td>\n",
       "      <td>2021-08-18 08:57:07</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>where s the dip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1427776452053901318</td>\n",
       "      <td>2021-08-17 23:36:47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i think people say that about people...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1427759906170548227</td>\n",
       "      <td>2021-08-17 22:31:02</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>ct is confidential to everyone except ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1427756195390136323</td>\n",
       "      <td>2021-08-17 22:16:18</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>confidential transactions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1427755868171509761</td>\n",
       "      <td>2021-08-17 22:15:00</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>i think for longer term cold storage people ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29796</th>\n",
       "      <td>1390026999792427009</td>\n",
       "      <td>2021-05-05 19:33:56</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>assumed that part was obvious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29797</th>\n",
       "      <td>1390025425124958210</td>\n",
       "      <td>2021-05-05 19:27:41</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>how it started</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29798</th>\n",
       "      <td>1390004608739647488</td>\n",
       "      <td>2021-05-05 18:04:58</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>save thread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29799</th>\n",
       "      <td>1389696368239775744</td>\n",
       "      <td>2021-05-04 21:40:08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>save thread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29800</th>\n",
       "      <td>1388758163407589376</td>\n",
       "      <td>2021-05-02 07:32:02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>save thread</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28322 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id           created_at  favorite_count  \\\n",
       "0      1427917464885682177  2021-08-18 08:57:07              10   \n",
       "1      1427776452053901318  2021-08-17 23:36:47               0   \n",
       "2      1427759906170548227  2021-08-17 22:31:02               3   \n",
       "3      1427756195390136323  2021-08-17 22:16:18              10   \n",
       "4      1427755868171509761  2021-08-17 22:15:00              13   \n",
       "...                    ...                  ...             ...   \n",
       "29796  1390026999792427009  2021-05-05 19:33:56               4   \n",
       "29797  1390025425124958210  2021-05-05 19:27:41             119   \n",
       "29798  1390004608739647488  2021-05-05 18:04:58               2   \n",
       "29799  1389696368239775744  2021-05-04 21:40:08               0   \n",
       "29800  1388758163407589376  2021-05-02 07:32:02               0   \n",
       "\n",
       "       retweet_count                                               text  \n",
       "0                  1                                 where s the dip     \n",
       "1                  0            i think people say that about people...  \n",
       "2                  0          ct is confidential to everyone except ...  \n",
       "3                  1                          confidential transactions  \n",
       "4                  1    i think for longer term cold storage people ...  \n",
       "...              ...                                                ...  \n",
       "29796              0                 assumed that part was obvious       \n",
       "29797              2                                   how it started    \n",
       "29798              0                                        save thread  \n",
       "29799              0                                        save thread  \n",
       "29800              0                                        save thread  \n",
       "\n",
       "[28322 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = df['created_at'] >= '2021-05'\n",
    "df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86586897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       where s the dip   \n",
       "1                  i think people say that about people...\n",
       "2                ct is confidential to everyone except ...\n",
       "3                                confidential transactions\n",
       "4          i think for longer term cold storage people ...\n",
       "                               ...                        \n",
       "29864                                          save thread\n",
       "29865                                          save thread\n",
       "29866                                          save thread\n",
       "29867                                                    h\n",
       "29868                                                     \n",
       "Name: text, Length: 29869, dtype: string"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18eef2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0ba1b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1427917464885682177</td>\n",
       "      <td>2021-08-18 08:57:07</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>where s the dip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1427776452053901318</td>\n",
       "      <td>2021-08-17 23:36:47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i think people say that about people...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1427759906170548227</td>\n",
       "      <td>2021-08-17 22:31:02</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>ct is confidential to everyone except ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1427756195390136323</td>\n",
       "      <td>2021-08-17 22:16:18</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>confidential transactions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1427755868171509761</td>\n",
       "      <td>2021-08-17 22:15:00</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>i think for longer term cold storage people ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29796</th>\n",
       "      <td>1390026999792427009</td>\n",
       "      <td>2021-05-05 19:33:56</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>assumed that part was obvious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29797</th>\n",
       "      <td>1390025425124958210</td>\n",
       "      <td>2021-05-05 19:27:41</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>how it started</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29798</th>\n",
       "      <td>1390004608739647488</td>\n",
       "      <td>2021-05-05 18:04:58</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>save thread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29799</th>\n",
       "      <td>1389696368239775744</td>\n",
       "      <td>2021-05-04 21:40:08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>save thread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29800</th>\n",
       "      <td>1388758163407589376</td>\n",
       "      <td>2021-05-02 07:32:02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>save thread</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28322 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id           created_at  favorite_count  \\\n",
       "0      1427917464885682177  2021-08-18 08:57:07              10   \n",
       "1      1427776452053901318  2021-08-17 23:36:47               0   \n",
       "2      1427759906170548227  2021-08-17 22:31:02               3   \n",
       "3      1427756195390136323  2021-08-17 22:16:18              10   \n",
       "4      1427755868171509761  2021-08-17 22:15:00              13   \n",
       "...                    ...                  ...             ...   \n",
       "29796  1390026999792427009  2021-05-05 19:33:56               4   \n",
       "29797  1390025425124958210  2021-05-05 19:27:41             119   \n",
       "29798  1390004608739647488  2021-05-05 18:04:58               2   \n",
       "29799  1389696368239775744  2021-05-04 21:40:08               0   \n",
       "29800  1388758163407589376  2021-05-02 07:32:02               0   \n",
       "\n",
       "       retweet_count                                               text  \n",
       "0                  1                                 where s the dip     \n",
       "1                  0            i think people say that about people...  \n",
       "2                  0          ct is confidential to everyone except ...  \n",
       "3                  1                          confidential transactions  \n",
       "4                  1    i think for longer term cold storage people ...  \n",
       "...              ...                                                ...  \n",
       "29796              0                 assumed that part was obvious       \n",
       "29797              2                                   how it started    \n",
       "29798              0                                        save thread  \n",
       "29799              0                                        save thread  \n",
       "29800              0                                        save thread  \n",
       "\n",
       "[28322 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[mask]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c818b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2ea250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480db653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aea527",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f1fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [re.sub('[%s]' % re.escape(string.punctuation), '', token) for token in tokens]\n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    lemmas = [lemmatiser.lemmatize(token) for token in tokens]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e249106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20544709",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = text.ENGLISH_STOP_WORDS.union(['don'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf879cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a743e489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f90083d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e22e2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tried Lemmatizing and Stemming, Lemmatizing seemed to give generally more understandable tokens\n",
    "#though lemmatizing did not decrease corpus size significantly \n",
    "def preprocess_text(text):\n",
    "    \"\"\"preprocessing text, tokenizing words that are strings longer than 2 letters\n",
    "    lemmatising tokens, adding new stopwords to stopwords list and removing all stopwords\"\"\"\n",
    "    from nltk.corpus import stopwords\n",
    "    #Tokenize words while ignoring punctuation\n",
    "    #letters only, strings longer than 2 letters\n",
    "    tokeniser = RegexpTokenizer(r'[A-Za-z]{3,}')\n",
    "    tokens = tokeniser.tokenize(text)\n",
    "     # lemmatise \n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    lemmas = [lemmatiser.lemmatize(token,pos='v') for token in tokens]\n",
    "    #ps=PorterStemmer()\n",
    "    #ports=[ps.stem(token.lower())for token in tokens]\n",
    "    \n",
    "    # Remove creating and removing stopwords\n",
    "    stopwords= stopwords.words('english')\n",
    "    new_stopwords=['don'] \n",
    "    stopwords.extend(new_stopwords)\n",
    "    keywords= [lemma for lemma in lemmas if lemma not in stopwords]\n",
    "    #keywords= [port for port in ports if port not in stopwords]\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72918a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e4f502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a60182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1578c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_topics(docs, preprocessor, vectorizer, topic_modeler, print_n_words=15):\n",
    "    \"\"\"A very simple pipeline.\"\"\"\n",
    "    \n",
    "    # Apply preprocessor, vectorizer, and topic modeler.\n",
    "    if preprocessor is not None:\n",
    "        docs = docs.apply(preprocessor)\n",
    "    \n",
    "    # Vectorize documents into a document-word matrix.\n",
    "    doc_word_vectors = vectorizer.fit_transform(docs)\n",
    "    \n",
    "    # Fit the topic model.\n",
    "    doc_topic_vectors = topic_modeler.fit_transform(doc_word_vectors)\n",
    "    \n",
    "    # Print the topics.\n",
    "    vocab = vectorizer.get_feature_names()\n",
    "    for idx, topic in enumerate(topic_modeler.components_):\n",
    "        # Select the top 15 words in vocab for this topic.\n",
    "        top_words = [vocab[i].upper() for i in topic.argsort()[:-print_n_words-1:-1]]\n",
    "        print(f\"Topic {idx}:\\n\", \", \".join(top_words), \"\\n\")\n",
    "    \n",
    "    return doc_topic_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a88f269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      " BITCOIN, FIXES, MONEY, BUY, WORLD, CRYPTO, TIME, FUTURE, ENERGY, YEARS, DIGITAL, FIAT, MINING, STANDARD, GOLD \n",
      "\n",
      "Topic 1:\n",
      " YES, EXACTLY, HELL, THANK, DID, AH, FUCK, ANSWER, PROBABLY, SIR, OK, READING, FREE, AGO, REALLY \n",
      "\n",
      "Topic 2:\n",
      " DON, LIKE, JUST, PEOPLE, KNOW, THINK, NEED, TIME, WANT, RIGHT, THANKS, MONEY, MAKE, WORK, LL \n",
      "\n",
      "Topic 3:\n",
      " LOL, DID, NICE, LOVE, OH, GREAT, SHIT, EXACTLY, THREAD, FAIR, USE, LITERALLY, TALK, REKT, TWEETS \n",
      "\n",
      "Topic 4:\n",
      " GOOD, MORNING, LUCK, POINT, MAN, LOOKING, IDEA, REALLY, DAY, THING, BAD, TIMES, TODAY, QUESTION, TIME \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "docs = df['text']\n",
    "preprocessor = None\n",
    "vectorizer = TfidfVectorizer(stop_words= 'english', min_df=5)\n",
    "topic_modeler = NMF(5, random_state=10, max_iter = 1000)  #random state to make the results deterministic\n",
    "\n",
    "make_topics(docs, preprocessor, vectorizer, topic_modeler);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58b3d308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338cca52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cde5dccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28322, 6099)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', min_df=5)\n",
    "doc_word = vectorizer.fit_transform(docs)\n",
    "doc_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "726ffdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<28322x6099 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 173433 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28ad2264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>aber</th>\n",
       "      <th>ability</th>\n",
       "      <th>abject</th>\n",
       "      <th>able</th>\n",
       "      <th>abolish</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absence</th>\n",
       "      <th>absolute</th>\n",
       "      <th>...</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zen</th>\n",
       "      <th>zero</th>\n",
       "      <th>zerobasefee</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zonte</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zu</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>where s the dip</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i think people say that about people who co founded the company  we invented it   a company being an organization of individuals to common purpose   hyperbitcoinization</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ct is confidential to everyone except sender and recipient as value and type are encrypted  federation block signers have no visibility just like your full node  only sender and recipient can decrypt  anyone can verify values add up due to use of additive homomorphic crypto  amp  zkp</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confidential transactions</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i think for longer term cold storage people would want   storage also  adoption looking good  just need more exchanges following   lead in deploying and reinvesting in  bitcoin    for more cross exchange transfer</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assumed that part was obvious</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>how it started</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>save thread</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>save thread</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>save thread</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28322 rows × 6099 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    abandon  abandoned  aber  \\\n",
       "text                                                                           \n",
       "    where s the dip                                       0          0     0   \n",
       "          i think people say that about people ...        0          0     0   \n",
       "        ct is confidential to everyone except s...        0          0     0   \n",
       "      confidential transactions                           0          0     0   \n",
       "  i think for longer term cold storage people w...        0          0     0   \n",
       "...                                                     ...        ...   ...   \n",
       "  assumed that part was obvious                           0          0     0   \n",
       "how it started                                            0          0     0   \n",
       "      save thread                                         0          0     0   \n",
       "    save thread                                           0          0     0   \n",
       "    save thread                                           0          0     0   \n",
       "\n",
       "                                                    ability  abject  able  \\\n",
       "text                                                                        \n",
       "    where s the dip                                       0       0     0   \n",
       "          i think people say that about people ...        0       0     0   \n",
       "        ct is confidential to everyone except s...        0       0     0   \n",
       "      confidential transactions                           0       0     0   \n",
       "  i think for longer term cold storage people w...        0       0     0   \n",
       "...                                                     ...     ...   ...   \n",
       "  assumed that part was obvious                           0       0     0   \n",
       "how it started                                            0       0     0   \n",
       "      save thread                                         0       0     0   \n",
       "    save thread                                           0       0     0   \n",
       "    save thread                                           0       0     0   \n",
       "\n",
       "                                                    abolish  abroad  absence  \\\n",
       "text                                                                           \n",
       "    where s the dip                                       0       0        0   \n",
       "          i think people say that about people ...        0       0        0   \n",
       "        ct is confidential to everyone except s...        0       0        0   \n",
       "      confidential transactions                           0       0        0   \n",
       "  i think for longer term cold storage people w...        0       0        0   \n",
       "...                                                     ...     ...      ...   \n",
       "  assumed that part was obvious                           0       0        0   \n",
       "how it started                                            0       0        0   \n",
       "      save thread                                         0       0        0   \n",
       "    save thread                                           0       0        0   \n",
       "    save thread                                           0       0        0   \n",
       "\n",
       "                                                    absolute  ...  zealand  \\\n",
       "text                                                          ...            \n",
       "    where s the dip                                        0  ...        0   \n",
       "          i think people say that about people ...         0  ...        0   \n",
       "        ct is confidential to everyone except s...         0  ...        0   \n",
       "      confidential transactions                            0  ...        0   \n",
       "  i think for longer term cold storage people w...         0  ...        0   \n",
       "...                                                      ...  ...      ...   \n",
       "  assumed that part was obvious                            0  ...        0   \n",
       "how it started                                             0  ...        0   \n",
       "      save thread                                          0  ...        0   \n",
       "    save thread                                            0  ...        0   \n",
       "    save thread                                            0  ...        0   \n",
       "\n",
       "                                                    zen  zero  zerobasefee  \\\n",
       "text                                                                         \n",
       "    where s the dip                                   0     0            0   \n",
       "          i think people say that about people ...    0     0            0   \n",
       "        ct is confidential to everyone except s...    0     0            0   \n",
       "      confidential transactions                       0     0            0   \n",
       "  i think for longer term cold storage people w...    0     0            0   \n",
       "...                                                 ...   ...          ...   \n",
       "  assumed that part was obvious                       0     0            0   \n",
       "how it started                                        0     0            0   \n",
       "      save thread                                     0     0            0   \n",
       "    save thread                                       0     0            0   \n",
       "    save thread                                       0     0            0   \n",
       "\n",
       "                                                    zeus  zombie  zone  zonte  \\\n",
       "text                                                                            \n",
       "    where s the dip                                    0       0     0      0   \n",
       "          i think people say that about people ...     0       0     0      0   \n",
       "        ct is confidential to everyone except s...     0       0     0      0   \n",
       "      confidential transactions                        0       0     0      0   \n",
       "  i think for longer term cold storage people w...     0       0     0      0   \n",
       "...                                                  ...     ...   ...    ...   \n",
       "  assumed that part was obvious                        0       0     0      0   \n",
       "how it started                                         0       0     0      0   \n",
       "      save thread                                      0       0     0      0   \n",
       "    save thread                                        0       0     0      0   \n",
       "    save thread                                        0       0     0      0   \n",
       "\n",
       "                                                    zoom  zu  \n",
       "text                                                          \n",
       "    where s the dip                                    0   0  \n",
       "          i think people say that about people ...     0   0  \n",
       "        ct is confidential to everyone except s...     0   0  \n",
       "      confidential transactions                        0   0  \n",
       "  i think for longer term cold storage people w...     0   0  \n",
       "...                                                  ...  ..  \n",
       "  assumed that part was obvious                        0   0  \n",
       "how it started                                         0   0  \n",
       "      save thread                                      0   0  \n",
       "    save thread                                        0   0  \n",
       "    save thread                                        0   0  \n",
       "\n",
       "[28322 rows x 6099 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff = pd.DataFrame(doc_word.toarray(), index=docs, columns=vectorizer.get_feature_names())\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e1b97c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = {'of', 'more', 'others', 'and', 'amoungst', 'ours', 'forty', 'elsewhere', 'own', 'anyone', 'but', 'becoming', 'fill', 'herself', 'both', 'their', 'will', 'all', 'less', 'two', 'many', 'four', 'eleven', 'them', 'towards', 'latterly', 'might', 'alone', 'himself', 'there', 'beforehand', 'three', 'again', 'must', 'whenever', 'move', 'across', 'empty', 'this', 'everywhere', 'seeming', 'those', 'therein', 'whole', 'these', 'yourself', 'while', 'to', 'co', 'me', 'fifty', 'for', 'my', 'its', 'still', 'sometimes', 'from', 'she', 'sincere', 'could', 'done', 'most', 'above', 'indeed', 'mostly', 'several', 'among', 'anyway', 'perhaps', 'only', 'twelve', 'give', 'between', 'after', 'an', 'when', 'you', 'into', 'put', 'meanwhile', 'over', 'our', 'well', 'during', 'also', 'other', 'nor', 'been', 'were', 'hundred', 'throughout', 'somehow', 'already', 'become', 'each', 'call', 'hereby', 'which', 'thereby', 'de', 'eg', 'full', 're', 'whereafter', 'on', 'they', 'sometime', 'namely', 'inc', 'detail', 'although', 'go', 'through', 'ltd', 'us', 'latter', 'against', 'her', 'everyone', 'then', 'so', 'can', 'any', 'see', 'ie', 'hers', 'anyhow', 'top', 'neither', 'hereafter', 'is', 'per', 'thereafter', 'how', 'a', 'get', 'be', 'yours', 'wherein', 'side', 'seemed', 'third', 'very', 'another', 'few', 'we', 'upon', 'whatever', 'sixty', 'would', 'beyond', 'con', 'math', 'same', 'had', 'ever', 'nothing', 'else', 'whether', 'becomes', 'off', 'enough', 'toward', 'one', 'afterwards', 'bill', 'i', 'next', 'thru', 'such', 'seem', 'whoever', 'together', 'hereupon', 'what', 'find', 'his', 'every', 'do', 'serious', 'everything', 'cannot', 'cant', 'under', 'without', 'eight', 'themselves', 'because', 'via', 'show', 'here', 'than', 'however', 'along', 'please', 'thus', 'twenty', 'herein', 'either', 'whither', 'nobody', 'with', 'became', 'who', 'may', 'keep', 'in', 'he', 'below', 'something', 'much', 'except', 'beside', 'whence', 'interest', 'whose', 'due', 'mill', 'behind', 'fifteen', 'otherwise', 'almost', 'nine', 'system', 'couldnt', 'back', 'rather', 'your', 'anything', 'front', 'nevertheless', 'seems', 'take', 'now', 'last', 'hasnt', 'myself', 'thence', 'about', 'wherever', 'somewhere', 'have', 'out', 'until', 'therefore', 'hence', 'yet', 'by', 'within', 'up', 'thick', 'where', 'am', 'further', 'five', 'should', 'least', 'since', 'ten', 'cry', 'around', 'none', 'always', 'anywhere', 'six', 'never', 'describe', 'him', 'has', 'once', 'not', 'onto', 'un', 'it', 'fire', 'before', 'that', 'often', 'amongst', 'being', 'someone', 'etc', 'if', 'some', 'no', 'whom', 'found', 'are', 'whereby', 'former', 'first', 'moreover', 'was', 'made', 'nowhere', 'as', 'mine', 'noone', 'though', 'or', 'yourselves', 'formerly', 'bottom', 'ourselves', 'itself', 'name', 'amount', 'part', 'down', 'the', 'whereas', 'thereupon', 'whereupon', 'besides', 'too', 'even', 'at', 'thin', 'why'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daedfe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "   \n",
    "    \n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc74464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tops = get_top_n_words(docs, n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27372048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "486a6d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tops = []\n",
    "for i in range(100):\n",
    "    if tops[i][0] not in stopWords:\n",
    "        new_tops.append(tops[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f227208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bitcoin', 4170),\n",
       " ('just', 1628),\n",
       " ('people', 1512),\n",
       " ('like', 1456),\n",
       " ('don', 1423),\n",
       " ('think', 903),\n",
       " ('good', 883),\n",
       " ('time', 866),\n",
       " ('money', 828),\n",
       " ('need', 735),\n",
       " ('know', 730),\n",
       " ('amp', 646),\n",
       " ('way', 581),\n",
       " ('want', 569),\n",
       " ('make', 551),\n",
       " ('right', 543),\n",
       " ('new', 520),\n",
       " ('yes', 518),\n",
       " ('going', 513)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dc985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe0ea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF(5)\n",
    "doc_topic = nmf_model.fit_transform(doc_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d5b3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb8b569",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word = pd.DataFrame(nmf_model.components_.round(5),\n",
    "             index = [\"component_1\",\"component_2\",\"component_3\",\"component_4\",\"component_5\"],\n",
    "             columns = vectorizer.get_feature_names())\n",
    "topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507244a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topics(nmf_model, vectorizer.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcb3286",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = pd.DataFrame(doc_topic.round(5), index=docs,\n",
    "                \n",
    "             columns = [\"component_1\",\"component_2\",\"component_3\",\"component_4\",\"component_5\"])\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb91f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "H.sort_values('component_3', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6440ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1386c8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "H.sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b6fc6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597d8e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "# Generate a word cloud image for given topic\n",
    "def draw_word_cloud(index):\n",
    "    \n",
    "    imp_words_topic = \"\"\n",
    "    components = nmf_model.components_[index]\n",
    "    vocab_comp = zip(vocab, components)\n",
    "    sorted_words = sorted(vocab_comp, key=lambda x:x[1], reverse=True)[:40]\n",
    "    \n",
    "    for word in sorted_words:\n",
    "        imp_words_topic = imp_words_topic + \" \" + word[0]\n",
    "\n",
    "    wordcloud = WordCloud(width=600, height=400).generate(imp_words_topic)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    " \n",
    "# draw all topics to compare\n",
    "for i in range(5):\n",
    "    draw_word_cloud(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03a8db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8e4803",
   "metadata": {},
   "outputs": [],
   "source": [
    "/anaconda3/bin/python -m pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a5cd13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
